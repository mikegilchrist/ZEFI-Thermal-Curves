---
title: "Piecewise Regression with NB Error on Simulated Data using BRMS"
author: "Michael Gilchrist"
date: "Created: 2023-01-12; Code run on `r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE, }

## Global options
options(digits = 3)

### Knitr specific
knitr::opts_chunk$set(
                      warning = TRUE, # show warnings
                      message = FALSE, # show messages
                      error = TRUE, # do not interrupt generation in case of errors,
                      echo = TRUE  # show R code
                      fig.width = 8,
                      fig.path = "Figures/"
                  )

options("warn" = 1) ## print warnings when they occur

if(interactive()) default::default(.ess.eval) <- list(max.deparse.length=5E1, output = TRUE)

```
# Goal

- Simulate realistic data based on data we have on `motif_count`.
- Fit two piece nb to simulated data using `brms` and possibly `rstan`.

## Recap

While `brms` can build and run the models, there are serious issues

- We get negative `mu` parameters for the NB.
- We get lots of `NaN` in the output
- I am unsure if I'm actually fitting the model as I intend.
For example, when using two groups for "x0", I don't get two estimates of "x0"
- I have failed to use male as a fundamental grouping beyond the `separate` setting.

# Set up

## Install libraries

```{r, message = FALSE}

# install packages user might not have by replacing FALSE with TRUE

## load libraries
library(stats)
library(MASS) # provides negative binomial fitting:  glm.nb
library(ggplot2)
library(ggpubr)
library(grid)
library(gridExtra)
library(GGally)
library(broom)
library(tidyverse)
library(viridisLite)
library(cmdstanr)
library(rstan)
options(mc.cores = 4) #(parallel::detectCores()-2))
rstan_options(auto_write = TRUE)
library(brms)
library(loo)
library(shinystan)


## options(ggplot2.continuous.colour="viridis",
##        ggplot2.discrete.colour="viridis",
##        ggplot2.scale_fill_discrete = scale_fill_viridis_d,
##        ggplot2.scale_fill_continuous = scale_fill_viridis_c)

library(reshape2)
library(lme4)
library(latex2exp)

```

## Load Data

```{r}
input_dir <- file.path("input")
output_dir <- file.path("output")

load(file.path(input_dir, "data.processing_2022-12-15.Rda"),
     verbose = TRUE)


motif_data
```
# Process Data
## Create Working Dataset

```{r}

filter_data <- TRUE

if(filter_data) {
    males_filtered_disp <- motif_stats_40C %>%
        filter(dispersion < 50) %>%
        pull(male)

    males_filtered_mean <- motif_stats %>%
        filter(mean > 10) %>% # changing from 10 to 40 removes previous male 7 (T258)
        pull(male)

    male_vector <- intersect(males_filtered_mean, males_filtered_disp)
} else {
    male_vector <- motif_data %>% select(male) %>% distinct()
}

data_ind <- motif_data %>%
    filter(male %in% male_vector) %>%
    mutate(male = droplevels(male)) %>%
    mutate(index = as.integer(male)) %>%
    mutate(male = as.character(male)) %>% 
    arrange(index) %>%
    select(male, index, motif_count, temp_target, temp, round, trial_round, date, counter) %>% 
    ##    left_join(index_shape, by = "index") %>%
    mutate()

stats_ind <- motif_stats %>%
    filter(male %in% male_vector) 


data_ind <- data_ind %>% filter(temp < 38) %>%
    group_by(male) %>% mutate(y0_simple.est = mean(motif_count), phi_ind = var(motif_count)/y0_simple.est) %>% ## phi is overdispersion parameter
    ungroup()

summary(data_ind)
n_male <- length(unique(data_ind$male))

## for calculation of 'theta_bar' (size in `rnbinom`) see note in `Set Up Simulate Data`
summary_stats <- data_ind %>% ungroup() %>%  summarize(y0_bar = mean(y0_simple.est), y0_sd = sd(y0_simple.est), phi_bar = median(phi_ind), theta_bar = y0_bar^2/(y0_sd^2 - y0_bar), ln_y0_bar = mean(log(y0_simple.est)),  log_y0_sd = sd(log(y0_simple.est)))
comment(summary_stats) <- "summary stats for observed bird motifs"

save(summary_stats, file = file.path(output_dir, "obs_summary_stats.Rda"))




```



## Create Simulated Dataset

- Simulation based on code from "code/2022-12-15_rstan_two.piece.qpoisson.with.simulated.data/rstan_twopiece_fit.various.models.to.simulated.data.Rmd"

From `rnbinom` help
>  An alternative parametrization (often used in ecology) is by the
>   _mean_ ‘mu’ (see above), and ‘size’, the _dispersion parameter_,
>   where ‘prob’ = ‘size/(size+mu)’.  The variance is ‘mu + mu^2/size’
>   in this parametrization.

So above we can estimate `size = mu^2/(var - mu)`.
We do this above in summary_stats `theta_bar = y0_bar^2/(y0_sd^2 - y0_bar)`.

### Functions Used

```{r}

sim_parms <- function(flag = "uniform_1", n_male = 10, mean_global = 100, sd = 10, n_sd = 2, min = 10, max = 600) {

    mean_low <- mean_global - n_sd * sd
    mean_high <- mean_global + n_sd * sd
    n_low <- ceiling(n_male/2)
    n_high <- n_male - n_low
    
    switch(flag,
           ## Parameter values are uniform across males within a category (high vs. low)
           uniform_1 = {
               tibble(parm = rep(mean_global, times = n_male), grp = 1L)},
           
           uniform_2 = {
               tibble(parm = c(rep(mean_low, times = n_low),
                               rep(mean_high, times = n_high)),
                      
                      grp =  c(rep(1L, times = n_low), 
                               rep(2L, times = n_high))
                      )},
           ## Parameter values vary between males, but pulled from distribution common to each category (high vs. low)
           ## Note syntax differs from model usage (this would 'be pooled')
           ## Should update model usage
           groups_1 = {
               tibble(parm = rnorm(n_male, mean_global, sd),
                      grp = 1L
                      )},
           groups_2 = {
               tibble(parm = c(rnorm(n_low, mean_low, sd),
                               rnorm(n_high, mean_high, sd)),
                      grp =  c(rep(1L, times = n_low),
                               rep(2L, times = n_high))
                      )}
           ) %>%
        mutate(bar = parm) %>% ## create record of mean value used
        mutate(sd = sd) %>% ## create record of mean value used
        mutate(parm = round(parm, 1)) %>%
        mutate(parm = pmax(min, parm)) %>% ## ensure parm is not below `min`
        mutate(parm = pmin(max, parm)) %>% ## ensure parm is not below `max`
                                        #mutate(parm = as.integer(parm)) %>%
        slice_sample(n = n_male, replace = FALSE) %>%
        mutate(index = row_number())
}

var_temp_mean <- function(temp_target) {
    ## Returns expected variance in temp_mean given temp_target
    ## numbers from analysis in `code/2023-01-13_temp_target.vs.var/compare.temp_target.vs.var.Rmd`
    var = max(0.891, -5.16 + 0.167 * temp_target)

    return(var)
}

sd_temp_mean <- function(temp_target) {
    sqrt(var_temp_mean(temp_target))
}

two_piece_model <- function(temp, y0, x0, xmax, theta) {
    ifelse(temp < x0, y0, y0 * (1-(temp-x0)/(xmax-x0)))
}

sim_nb_counts <- function(temp, y0, x0, xmax, theta) {
    ## Calculate expected value given parametes
    mu <- two_piece_model(temp, y0, x0, xmax, theta)
                                        #print(paste("size: ", size, "count: ", count))
    rnbinom(1, size = theta, mu = mu)
}


sim_qpoisson_counts <- function(temp, y0, x0, xmax, phi) {

    ## Calculate expected value given parametes
    mu <- two_piece_model(temp, y0, x0, xmax, theta)
    
    ## calculate theta parameter based on mu and phi
    theta = mu/(phi - 1)
                                        #print(paste("size: ", size, "count: ", count))
    rnbinom(1, size = theta, mu = mu)
}


```

### Generate Parameter Tibble

- Parameter values in this tibble will be used to create simulated data.

```{r}


parms_sim_file <- file.path(output_dir, "parms_sim_tbl")
data_sim_file <- file.path(output_dir, "data_sim_tbl")
recreate_simulated_data <- TRUE

phi <- summary_stats$phi_bar ## overdispersion parameter
theta <- summary_stats$theta_bar ## size parameter
y0_bar <- summary_stats$y0_bar ## make slightly larger
y0_sd <- summary_stats$y0_sd/3 ## assume there's more than one population and so make it smaller
x0_bar <- 39 ## based on vague prior knowledge
x0_sd <- 1 ## ditto
xmax <- 46
n_male <- 12

## Simulate data if it doesn't exist or if desired

if( ! file.exists(data_sim_file) | recreate_simulated_data) {
    ## Generate 'true' parameters
    ## If TRUE, replace estimated y_0 with simulated values,
    ## else use estimates from observed data 
    y_flags <- c("uniform_1", "uniform_2", "groups_1", "groups_2")
    x_flags <- y_flags

  data_sim <- tibble()
  parms_sim <- tibble()

    replicates <- c(3, 8, 32)
    temp_target <- c(30, 38, 40, 42, 44)

    set.seed(2023) # was originally 2022

    for(sampling_dist in c("qpoisson", "nb")) {
        for(x_flag in x_flags) {
            for(y_flag in y_flags) {
                for(n_reps in replicates) {

                    y0_sim <- sim_parms(flag = y_flag, n_male = n_male, mean = y0_bar, sd = y0_sd, n_sd = 3) %>%
                      rename(y0 = parm, y0_group = grp, y0_bar = bar, y0_sd = sd)
                  
                    x0_sim <- sim_parms(flag = x_flag, n_male = n_male, mean = x0_bar, sd = x0_sd, min = 35, max = 45.9)  %>%
                        rename(x0 = parm, x0_group = grp, x0_bar = bar, x0_sd = sd)
                    
                    x0_y0_sim <- full_join(x0_sim, y0_sim, by = "index") %>%
                        relocate(index) %>% ## move index to first column
                        mutate(x0_group = factor(x0_group),
                               y0_group = factor(y0_group),
                               index = factor(index))

                    ## Create relevant subset data matrix
                    parms_tmp <- crossing(sampling_dist = sampling_dist,
                                          x0_y0_sim,
                                          temp_target = temp_target,
                                          n_reps = n_reps,
                                          rep = 1:n_reps,
                                          x_flag = x_flag,
                                          y_flag = y_flag)

                    parms_tmp <- parms_tmp %>%
                        rowwise() %>%
                        mutate(temp_sd = sd_temp_mean(temp_target),
                               temp_mean = min(rnorm(1, mean = temp_target, sd = temp_sd), 45.9)) %>% 
                        select(-temp_sd)

                    summary(parms_tmp)
                    
                    data_tmp <- switch(sampling_dist,
                                       qpoisson = {
                                           parms_tmp %>%
                                               mutate(motif_count= sim_qpoisson_counts(temp_mean, y0, x0, xmax, phi))},
                                       nb = {
                                           parms_tmp %>%
                                               mutate(motif_count = sim_nb_counts(temp_mean, y0, x0, xmax, theta))
                                       }

                                       )
                    
                    if(nrow(data_sim) == 0) {
                        data_sim <- data_tmp
                    } else {
                        data_sim <- bind_rows(data_sim, data_tmp)
                    }

                  if(nrow(parms_sim) == 0) {
                        parms_sim <- parms_tmp
                    } else {
                        parms_sim <- bind_rows(parms_sim, parms_tmp)
                    }

                }
            }
        }
    }

    ## undo 'rowwise'
    data_sim <- data_sim %>% ungroup()

    save(data_sim, file = data_sim_file)
    save(parms_sim, file = parms_sim_file)
} else {
    load(data_sim_file)
    #load(parms_sim_file)
}

```

### Plot Parameters

```{r plot_parameters}

sampling_d <- "nb"
n_reps <- replicates[[1]]

## Use `rlang` injection paradigm
## `!!` tels R to evaluate argument before evaluating function, so it uses the
## variable defined in the .globalEnvironment() rather than . of filter
## See  https://stackoverflow.com/a/47171513/5322644
parms_tmp <- parms_sim %>%
  filter(sampling_dist == !!sampling_dist,
         n_reps == !!n_reps)

data_tmp <- data_sim %>%
  filter(sampling_dist == !!sampling_dist,
         n_reps == !!n_reps)

dim(parms_tmp)

x_flag <- "groups_2"
y_flag <- "groups_2"

parms <- parms_tmp %>% filter(x_flag == !!x_flag, y_flag == !!y_flag) %>%
  select(-c(temp_mean, temp_target, rep)) %>%
  unique()
dim(parms)

data <- data_tmp %>% filter(x_flag == !!x_flag, y_flag == !!y_flag)
dim(data)


p <- ggplot(parms)

hist_x0_vals <- p + 
    aes(x0, fill = x0_group) +
  geom_histogram(binwidth = 0.75) 
last_plot()

hist_y0_vals <- p +
    aes(y0, fill = y0_group) +
    geom_histogram(binwidth = 25)
last_plot()

scatter_x0_vs_y0 <- p +
  aes(x = x0, y = y0, color = interaction(x0_group, y0_group, sep=':')) + 
  geom_point() +
    guides(color=guide_legend(title="groups\n  x0_group:y0_group"))
  last_plot()


plot <- ggplot(data) +
  aes(y = motif_count, x = temp_mean, color = index) +
  geom_point() +
  facet_grid(rows = vars(x0_group), cols = vars(y0_group)) #, scales = "free_y")
last_plot()

```


# Fit Models

## Common Parameters

```{r}

xmax <- 46
x0max <- xmax - 0.5;
x0min <- 20;

y_xmax <- 0
y0_min <- 10
sd_y0_prior <- 200
alpha_theta_prior <- 10 ## exponential dist scale parameter for overdispersion theta in quasipoisson
alpha_phi_prior <- 0.01 ## gamma dist shape parameter for nb. brms default is 0.01
beta_phi_prior <- 0.01 ## gamma dist rate parameter for nb. brms default is 0.01


## values to use for model predictions
x_for_predictions = seq(25, xmax, length.out = 100)
n_cores <- 4
n_chains <- n_cores
```
## Simulated Data


### Analyze `x ~ groups_1|2, y ~ groups_1|2`

#### Set Up Data


##### Data `sampling_dist`, `x0`, and `y0`: "nb", "groups_2", "groups_2"
```{r}


x_flag_data <- "groups_2"
y_flag_data <- "groups_2"
sampling_dist_data <- "nb"
n_reps <- 32

data_base <- data_sim %>% filter(x_flag == x_flag_data,
                            y_flag == y_flag_data,
                            sampling_dist == sampling_dist_data,
                            n_reps == !!n_reps) %>%
    rename(temp = temp_mean, male = index) %>%
    rename(y = motif_count, x = temp) 

```

#### Fit Model


##### Analysis `sampling_dist`, `x0`, and `y0`: "nb", "uniform_z", "groups_z"

Working with `groups_2; nb` data

```{r}
adapt_delta <- 0.95 #0.95
iter <- 2000
thin <- 1

## could include "individual"
flags <- c("uniform_1", "uniform_2", "groups_1", "groups_2")
models <- c("brms")
sampling_dist_fit <- "nb"
flags_x <- flags
flags_y <- flags
N <- length(data)

fit_tbl <- crossing(model = models,
                    sampling_dist = sampling_dist_fit,
                    x0_flag = flags_x, y0_flag = flags_y,
                    desc = "NA_character",
                    y0_group_list = list(NA), #tbl_tmp, #list(NA),
                    x0_group_list = list(NA),
                    fit = list(NA),
                    llik = list(NA),
                    r_eff = list(NA),
                    loo = list(NA)
                    )

## Priors

my_priors <- prior(
  # uniform(10, 1000), nlpar = "y0", lb = 10) +
  normal(150, 200), nlpar = "y0", lb = 10) +
  prior(uniform(30, 45.5), lb = 30, ub = 45.5, nlpar = "x0")


model = models[[1]]

for(x_flag in flags_x) {
    for(y_flag in flags_y) {

        ## Set up variables for saving model and fit
        desc <- paste0(model, ": ", x_flag, ", ", y_flag)
        curr_row <- which(fit_tbl$model == model &
                          fit_tbl$x0_flag == x_flag &
                          fit_tbl$y0_flag == y_flag)
        fit_tbl[ curr_row, ]$desc <- desc

      print(desc)
      ## Refresh data in case x0_group or y0_group are all set to 1
      data <- data_base

      ## Set flags based on fitted model structure
      if(x_flag %in% c("uniform_1", "groups_1")) data <- mutate(data, x0_group = 1)
      if(y_flag %in% c("uniform_1", "groups_1")) data <-mutate(data, y0_group = 1)
      if(x_flag %in% c("individual")) data <- mutate(data, x0_group = male)
      if(y_flag %in% c("individual")) data <- mutate(data, y0_group = male)



      ## Note we need to put a tibble into a list because row updates, even if doing
      ## just one cell, require a list format.
      fit_tbl[[curr_row, "x0_group_list"]] <- list(unique(data[, c("male", "x0_group")]))
      fit_tbl[[curr_row, "y0_group_list"]] <- list(unique(data[, c("male", "y0_group")]))

        ## Parameter Structure
        x_form <- switch(x_flag,
                         uniform_1 = formula(x0 ~ 1),
                         uniform_2 = formula(x0 ~ 1 + x0_group),
                         # Don't include x0_group info which is determined by the data set
                         groups_1 = formula(x0 ~ (1||male)), 
                         groups_2 = formula(x0 ~ (1||male) + x0_group),
                         individual = formula(x0 ~ -1 + male)
                         )
        
        y_form <- switch(y_flag,
                         uniform_1 = formula(y0 ~ 1),
                         uniform_2 = formula(y0 ~ 1 + y0_group),
                         groups_1 = formula(y0 ~ (1|| male)), 
                         groups_2 = formula(y0 ~ (1|| male) + y0_group),
                         individual = formula(y0 ~ -1 + male)
                         )
        nlform <- bf(
            y ~  0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0),
            x_form,
            y_form,
            nl = TRUE)

        if(TRUE) print(get_prior(nlform, data = data, family = negbinomial(link = "identity", link_shape = "identity")))

#    }}
##
#```
#
#```{r}
        fit <- brm(nlform,
                   data = data,
                   ## `link` refers to the mapping of the expectation of the distribution: log, sqrt, identity, softplus
                   ## link_shape corresponds to `phi` of `stan`'s
                   ## Negbinomial_2
                   ## Defining `phi = mu/theta` creates a quasipoisson
                   ## distribution with overdispersion parameter (1 +theta)
                   family = negbinomial(link = "identity", link_shape = "identity"),
                   prior = my_priors,
                   iter = iter,
                   thin = 2,
                   silent = ifelse(interactive(), 1, 2), # 0, 1, or 2. 1 is default
                   control = list(adapt_delta = adapt_delta,
                                  max_treedepth = 12),
                       ## Only print out sampling progress if in interactive mode
                   refresh = ifelse(interactive(),max(iter/10, 1), 0),
        chains = n_chains,
        cores = n_cores,
        save_model = "brms_two.piece.stan")
    ## Avoid having brms recompile model by defining
    ## model in global environment
    stanfit <- fit
stan    
                                        #fit_exp <- expose_functions(fit) , vectorize = TRUE)
                                        #fit_cr <- add_criterion(fit_exp, c("loo", "waic"))
    print(fit)     
    fit_tbl[ curr_row, ]$fit <- list(fit)

    ## Print and then clear warnings
    warnings(summary)
    warning(immediate. = FALSE)
save(file = file.path(output_dir, paste0("fit_tbl_data.Rda-tmp")), fit_tbl)
    }
}

save(file = file.path(output_dir, paste0("fit_tbl_data_", x_flag_data, "_", y_flag_data, "_n_reps_", n_reps, ".Rdata")), fit_tbl)

```

##### Output from model fits

- Text indicating model is repeatedly recompiled has been removed.


###### Analysis of `groups_1` Data

```{verbatim}

"brms: individual, individual"

STARTING SAMPLER FOR MODEL 'anon_model' NOW.
Family: negbinomial 
Links: mu = identity; shape = identity 
Formula: y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0) 
x0 ~ -1 + male
y0 ~ -1 + male
Data: data (Number of observations: 1920) 
Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
total post-warmup draws = 4000

Population-Level Effects: 
Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
x0_male1     36.71      0.95    34.59    38.31 1.00     3962     2515
x0_male2     39.84      0.73    38.21    41.11 1.00     4141     2758
x0_male3     38.62      0.83    36.95    40.09 1.00     4203     2884
x0_male4     36.28      1.36    33.46    38.56 1.00     3494     2213
x0_male5     38.41      0.91    36.30    39.92 1.00     3652     2013
x0_male6     41.94      0.40    41.13    42.70 1.00     5015     3010
x0_male7     40.62      0.66    39.23    41.81 1.00     3883     2603
x0_male8     39.76      0.54    38.65    40.83 1.00     4593     2903
x0_male9     38.83      0.68    37.33    40.06 1.00     3720     2208
x0_male10    34.97      1.28    32.20    37.23 1.00     3959     2235
x0_male11    38.35      0.92    36.35    39.92 1.00     3594     2494
x0_male12    37.60      0.93    35.60    39.24 1.00     4784     2653
y0_male1    203.65     18.38   172.07   245.09 1.00     4081     2287
y0_male2     64.66      4.94    56.13    75.63 1.00     4234     2683
y0_male3    255.97     21.00   220.31   301.97 1.00     4173     3255
y0_male4     56.43      6.57    45.23    70.94 1.00     3480     2279
y0_male5    138.49     12.72   117.90   166.93 1.00     3438     1854
y0_male6    194.18     10.38   174.98   215.31 1.00     5181     3374
y0_male7     47.21      3.31    41.53    54.58 1.00     4037     2942
y0_male8     66.33      4.11    58.96    75.13 1.00     4298     2202
y0_male9    167.19     12.86   145.12   195.89 1.00     3663     2052
y0_male10    39.47      4.02    32.34    48.28 1.00     3882     2193
y0_male11   135.30     12.28   115.05   163.19 1.00     3690     2485
y0_male12    11.18      1.03     9.44    13.46 1.00     4690     2752

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
shape     3.16      0.11     2.95     3.39 1.00     6356     2791

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).


[1] "brms: individual, groups_1"
Warning: There were 1 divergent transitions after warmup. See
https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup

Family: negbinomial 
  Links: mu = identity; shape = identity 
FormOBBula: y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0) 
         x0 ~ -1 + male
         y0 ~ (1 || male)
 AOA  DBata: data (Number of observations: 1920) 
~  DrawsOB: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~male (Number of levels: 12) 
          OBB       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(y0_Intercept)    79.47     17.63    53.35   120.20 1.01     1025     1510

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
x0_male1        36.90      0.89    34.95    38.40 1.00     4360     2100
x0_male2        39.84      0.71    38.34    41.14 1.00     6063     2805
x0_male3        38.90      0.77    37.37    40.22 1.00     5115     2939
x0_male4        36.22      1.38    33.29    38.54 1.00     4729     1931
x0_male5        38.47      0.88    36.52    39.96 1.00     4562     2180
x0_male6        41.96      0.39    41.18    42.70 1.00     5524     2704
x0_male7        40.60      0.68    39.20    41.82 1.00     6539     2973
x0_male8        39.74      0.55    38.63    40.81 1.00     5978     2674
x0_male9        38.89      0.64    37.53    40.06 1.00     4379     2072
x0_male10    BOB   34.86      1.29    32.10    37.16 1.00     3517     1535
x0_male11       38.38      0.89    36.52    39.91 1.00     4700     3019
x0_male12       37.57      0.95    35.46    39.24 1.00     6090     2482
y0_Intercept   113.58     23.65    66.58   161.39 1.00      673     1110

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
shape     3.16      0.11     2.95     3.37 1.00     5899     3261

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction OBBfactor on split chains (at convergence, Rhat = 1).

B
[1] "brms: groups_1, individual"

SOB:ODOODODODODD SAMPLER FOR MODEL 'anon_model' NOW.
 Family: negbinomial 
  Links: mu = identity; shape = identity 
Formula: y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0) 
         x0 ~ (1 || male)
         y0 ~ -1 + male
   Data: data (Number of observations: 1920) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~male (Number of levels: 12) 
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(x0_Intercept)     1.94      0.56     1.11     3.33 1.00     1573     2117

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
x0_Intercept    38.66      0.66    37.30    39.87 1.00     1521     2104
y0_male1       BOB196.56     15.51   169.69   230.59 1.00     5089     2429
y0_male2        65.37      4.86    56.63    75.99 1.00     5114     3014
y0_male3       255.48     20.14   221.03   297.36 1.00     5183     3093
y0_male4        52.41      5.18    44.11    64.23 1.00     4203     3194
y0_male5       137.23     11.29   118.18   162.25 1.00     4677     2431
y0_male6       196.18     10.53   177.03   218.01 1.00     5688     2252
y0_male7        48OBOBOB.15      3.38    42.22    55.27 1.00     5018     2311
y0_male8        66.73      4.08    59.38    75.27 1.00     6890     2734
y0_male9       167.08     12.05   146.34   193.20 1.00     5657     2651
y0_male10       36.45   OBOB   3.29    30.75    43.43 1.00     4483     2649
y0_male11      134.29     11.14   114.90   158.91 1.00     4292     3117
y0_male12       10.98      0B.95     9.26    13.11 1.00     5302     2654
5F







t
Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
shape     3.16      0.11     2.95     3.38 1.00     8311     2839

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).


[1] "brms: groups_1, groups_1"
 Family: negbinomial 
  Links: mu = identity; shape = identity 
Formula: y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0) 
         x0 ~ (1 || male)
         y0 ~ (1 || male)
   Data: data (Number of observations: 1920) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~male (Number of levels: 12) 
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(x0_Intercept)     1.90      0.56     1.10     3.29 1.00     1520     2195
sd(y0_Intercept)    79.31     17.07    52.91   119.09 1.00     1126     1904

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
x0_Intercept    38.72      0.63    37.41    39.95 1.00     1297     1459
y0_Intercept   113.89     23.82    66.15   161.34 1.00      634     1000

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
shape     3.16      0.11     2.95     3.38 1.00     4387     3042

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).

```

#### Generate useful plots

```{r}

## Define fmax() which is used in the model and needs to be defined within R.
## Ideally this would be done via expose_functions() in `brms`, but that's not working.
gmax <- function(a, b) max(a,b)

fmax <- Vectorize(max)

plot(conditional_effects(fit), points = TRUE)

```

#### Compare Parameter Estimates to Truth

