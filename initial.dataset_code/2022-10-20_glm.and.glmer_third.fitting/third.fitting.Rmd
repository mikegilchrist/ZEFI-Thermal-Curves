---
title: "Third Fitting of Thermal Models"
author: "Michael Gilchrist"
date: "date: 2022-10-20"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = TRUE, # show warnings
  message = TRUE, # show messages
  error = TRUE, # do not interrupt generation in case of errors,
  echo = TRUE  # show R code
)
```
# Goal

- Fit series of thermal models, including, ultimately, those found in `rTPC` to data collected in the Derryberry lab.

## Recap

Previous work suggests that

- Temp is hard to control in chambers, so we should work with `temp_mean` (mean value during trial), not `temp_target`.
- `humidity_mean` and `temp_mean` strongly co-vary so consider using aggregate index as explanatory variable
  - Vapor Pressure Deficit (provided by `humidity` package)
  - Heat Index (formulated for humans, and provided by `weathermetrics`)
- Round 3 data only for curve fitting
  - Only round where `temp_mean` and `humidity_mean` exist.
- `count_total_round` are consistent between Rounds 1 and 3, so could use that info to classify birds, estimate variance function in response, etc.
- One bird in `round = 3` collapsed during the trial so it was terminated.
  We've set the `motif_count` from NA to 0 and should consider making at `temp_working` column using `temp_target` in this instance and `temp_mean` in all other instances.
  Would need to do something similar for relative humidity, i.e. use `mean(humidity_mean)` for the `temp_target` value.
  
## Current Work

- Created `temp` and `humidity` variables from `temp_mean` and `humidity_mean` for males who didn't collapse, used `mean(temp_mean)` and `mean(humidity_mean)` values for one male that did.
- Copied `data_full` and set  `male = "combined"` so we could look at all of the data at once.
- Learned about using `model` argument for glm models
- Can't fit ME models
  - I don't understand why the ME model with `motif_count` where we use a RE for the intercept doesn't have a similar effect as using motif_prop.
    This intercept value is essentially multiplying by a constant, so we could try and specify this value using `offset(log(count_total_round))`.
    So why doesn't this work?

## Next Steps

### Which Explanatory Variable: temp, humidity, vpd?

- Liz will look into operative temp
- Use of `vpd_mean` is somewhat arbitrary since it depends on the experimental design.
  - Use of 0 reference in vpd seems less arbitrary than using 0 C.
- Note that we could scale temp_mean relative to C = 45, which is the understood thermal maximum.
  - This is what Liz wants to do since it's easier to interpret

### Including beak and mass data

- Include beak size (surface area) as additional explanatory variable.
  We do have bird mass as well
- Notes from Liz
  - Do birds with larger beaks maintain singing at higher rates at higher temps? 
  - We calculated bill surface area approximately as the surface area of a cone: length * pi * (width + depth) / 4.
  - Because larger animals produce more heat (Kleiber 1932), we scaled bill size relative to heat production by dividing bill surface area by expected daily energy consumption (mass0.658; Speakman and Kr´ol 2010, Hudson et al. 2013).
  - So, looks like we need to calculate bill surface area and then scale relative to heat production (bill surface area/mass0.658)

### Type of Model Fitted

- Don't worry about random effects for now
- Try the quadratic fit with just temperature and the 0 set at 45C. 
  - Quadratic function – pull out the peak, the curvature at the peak, calculate the intercept at some temp – what is the intercept
- Begin fitting rTPC models to combined dataset.


### Using Data from Rounds 1 and 2

- Liz: Ask Kayci about `temp_mean` and `humidity_mean` data for rounds 1 and 2.
- Look for order effects in round 1 and 2? 
  Can we use any of this data? 
  Seems like there will be an issue if we throw out, say, first two trials, when using `motif_prop`.
  Note that since total_count is consistent for a bird between rounds, this may not be an issue.
- Begin fitting rTPC models to combined dataset.
- We could include round = 2
  - Would need to down weight motif_count values when combining across  `count_total_round` values.


#### Additional Liz

- Follow up with Ray/Juan about ground versus surface temp for operative temperature.
- What is the 0 for operative temperature?
- Ponder utility of other ZF data on panting.


# Set up

## Install libraries

```{r}

## install packages user might not have by replacing FALSE with TRUE
if(FALSE) {
    BiocManager::install("mixOmics") ## needed by RVAideMemoire
    install.packages(c("RSQLite", "nls.multstart", "lme4", "RVAideMemoire"))
    ##  Install the thermal curve package from git_hub, not cran
    remotes::install_github("padpadpadpad/rTPC")

}

## load libraries
library(stats)
require(MASS) # provides negative binomial fitting:  glm.nb
library(RSQLite)  # Don't think we need this.
library(rTPC)  ## 
library(nls.multstart)
library(broom)
library(tidyverse)
require(ggplot2)
require(ggpubr)
require(viridisLite)

#options(ggplot2.continuous.colour="viridis",
#        ggplot2.discrete.colour="viridis",
#        ggplot2.scale_fill_discrete = scale_fill_viridis_d,
#        ggplot2.scale_fill_continuous = scale_fill_viridis_c)

require(GGally)
require(reshape2)
require(lme4)
require(RVAideMemoire) # provides overdisp.glmer()
require(humidity) ## provides VPD
require(weathermetrics)
require(latex2exp)

```

## Load Data

```{r}

## Read in ZEFI Data sets
## Treat 'repeatability' as round = 0
## Add round info

## Repeatability was done between round 1 and 2, female was present, but only one temp. so treating as `round = 2` and redefining `round = 2` as `round = 3`

git_root <- system("git rev-parse --show-toplevel", intern = TRUE)

data_raw = list()

data_raw[[1]] <- read.csv(file.path(git_root, "data", "collated", "HSPi-Round-1-Heat-Trials.csv")) %>% mutate(round = 1) %>%
    ## Note T237 and T230 are missing numbers in the motif_count column
    ## so we are filtering these observations out until they are found
    filter(!is.na(motif_count))

data_raw[[2]] <- read.csv(file.path(git_root, "data", "collated", "HSPi-Repeatability-Song-Count.csv")) %>%
    mutate(round = 2) %>%
    group_by(male) %>%
    mutate(test_order = rank(date)) %>%
    ungroup()

data_raw[[3]] <-read.csv(file.path(git_root, "data", "collated", "HSPi-Round-2-Heat-Trials.csv")) %>%
    mutate(round = 3) %>%
    ## Deal with missing temp_mean and humidity_mean values
    ## in round == 3
    ## 2022/10/19 - code no longer needed
    ## group_by(temp_target) %>% 
    ##mutate(temp = if_else((round == 3 & is.na(temp_mean)),
    ##                      mean(temp_mean, na.rm = TRUE),
    ##                      temp_mean)) %>%
    ##mutate(humidity = if_else((round == 3 & is.na(humidity_mean)),
    ##                          mean(humidity_mean, na.rm = TRUE),
    ##                          humidity_mean)) %>%
    ungroup() 


## Join data and discard empty columns
data_full <- full_join(data_raw[[1]], data_raw[[2]]) %>%
    full_join(data_raw[[3]]) %>%
    discard(~all(is.na(.) | . =="")) %>% ## get rid of columns of only NA
    mutate(trial_completed = !(is.na(motif_count)) ) %>%
    mutate(motif_count = ifelse(is.na(motif_count), 0, motif_count)) %>%
    mutate(motif_count = motif_count*1.0) %>% ## convert to a double so it's not treated as an integer
    mutate(chamber = as.factor(chamber), male = as.factor(male)) %>%
    ## create a global variable trial_order based on individual rounds
    mutate(trial_index = as.integer(round*10+test_order)) %>%
    mutate(motif_count_plus_1 = (motif_count + 1)) %>%
    mutate(log_motif_count_plus_1 = log(motif_count + 1)) %>%
    mutate(temp_target = as.numeric(temp_target)) %>%
    ## Add column with total motif_count for a given round
    group_by(male, round ) %>%
    mutate(count_total_round = sum(motif_count) ) %>%
    ungroup() %>%
    mutate(motif_prop = motif_count/count_total_round) %>%
    ## assuming poisson error
    ## From glm man page
    ## > Non-‘NULL’ ‘weights’ can be used to indicate that different
    ## >  observations have different dispersions (with the values in
    ## >  ‘weights’ being inversely proportional to the dispersions);
    ## add +1 to deal with single 0
    mutate(count_wt = 1/(motif_count + 1)) %>%
    ## need to rescale wts for motif_prop data
    mutate(prop_wt = count_wt * count_total_round^2) %>% 
    ## Add vpd 
    mutate(svp = SVP(t = temp_mean + 273.15, isK = TRUE), vpd = svp*(1-humidity_mean/100) ) %>%
    group_by(round) %>%
    mutate(vpd_offset = vpd - mean(vpd)) %>%
    ungroup() %>%
    relocate(motif_count, motif_prop, vpd, temp_mean, humidity_mean, .after = male) %>% 
    mutate() ## Dummy function so we can comment out lines above it w/o any issues


```

# Third Analysis for Liz


## Examine Data

```{r}

data_count_total <- data_full %>% group_by(round) %>%
    select(male, round, count_total_round)  %>%
    distinct()

t <- ggplot(data_count_total, aes(count_total_round, fill = male)) +
    geom_histogram(bins = 10) +
    scale_x_log10()

hist_count_total <- t +
    facet_grid(cols =vars(round), scales = "free_x")
hist_count_total



```
## Compare `count_total_round` between round 1 and 3

```{r}

count_total_by_round <- data_full %>%
      select(male, round, count_total_round) %>%
      unique() %>%
      pivot_wider(names_from = round, values_from = count_total_round)


## Modified from https://stackoverflow.com/a/68553749/5322644
diag_plots <- function(data, mapping, ...) {
    ggplot(data = data, mapping = mapping) +
        # choose color by counter and send bin width argument in
        geom_histogram(...)
}

# pairs plot
ggpairs(count_total_by_round %>% select(-male),
        diag = list(continuous = wrap(diag_plots, bins = 8))
        )


```

### Result

- As before, we see strong consistancy between `round` 1 and 3.
- Consistency with round 2 is weaker, but sample sizes are smaller: 3 trials/male in round 2 vs 6 trials/male in round 3.

  

## Create & Plot Filtered Data

```{r}

data_ind <- data_full %>%
    filter(round==3) %>%
    filter(count_total_round >=150)
## copy data frame and assign `male =  "combined")
data_comb <- data_ind %>% mutate(male = "combined")

data <- bind_rows(data_ind, data_comb)

xlab <- "Temperature"
ylab <- "motif_count"

plot_temp_data <-
    ggplot(data) + 
    aes(x = temp_mean,
        y = motif_count) +
    facet_wrap("male", scales = "free_y") +
    geom_point() +
labs( title = paste( ylab, " vs ", xlab))
last_plot()


## Create again for humidity

xlab <- "humidity"

plot_humidity_data <-
    ggplot(data) + 
    aes(x = humidity_mean,
        y = motif_count) +
    facet_wrap("male", scales = "free_y") +
    geom_point() +
labs( title = paste( ylab, " vs ", xlab))
last_plot()

## Create for vpd

xlab <- "vpd"

plot_vpd_data <-
    ggplot(data) + 
    aes(x = vpd,
        y = motif_count) +
    facet_wrap("male", scales = "free_y") +
    geom_point() +
    labs( title = paste( ylab, " vs ", xlab))
last_plot()


```


## Work with mean and motif_prop 

- This approach won't work because `temp_target` varies greatly from `temp_mean`.



```{r}

plot_combine <- ggplot(data_ind) +
                  aes(x = temp_mean, y = motif_prop, color = male) +
                  geom_point()
# last_plot()

data_summarize <-
    data_ind %>% group_by(temp_target) %>%
    summarize(motif_mean = mean(motif_prop),
              motif_sd = sd(motif_prop),
              motif_n= dplyr::n(),
              motif_se = motif_sd/sqrt(motif_n),
              motif_ci = motif_se*1.96
              )


plot_summarize <- ggplot(data_summarize) +
    aes(x = temp_target, y = motif_mean) +
    geom_point()+
    geom_errorbar(aes(ymin=motif_mean - motif_ci, ymax=motif_mean+motif_ci), width=.2)
# last_plot()
              
plot_combine +
    geom_point(data = data_summarize, aes(x = temp_target, y = motif_mean, colour = "Mean & CI"))+
    geom_errorbar(data = data_summarize, aes(x = temp_target,
                                             y = motif_mean,
                                             ymin=motif_mean - motif_ci,
                                             ymax=motif_mean+motif_ci,
                                             colour= "Mean & CI"), width=.2) + 
    labs(title = "Mean(motif_prop) vs. temp_target with 95% CI for mean",
         subtitle = "Individual motif_prop vs. temp_mean also plotted")


```

### Result

- Data is noisy.
- Using `motif_prop` reduces impact of male `T225` on lower temps.
- Note `temp_target` is not necessarily accurate.



## Humidity, Temp, and VPD


### Previous Results from `second.fitting.pdf`

- Values clearly co-vary.
- Should consider using
  - Vapor Pressure Deficit
    - Uses temp to calculate max humidity and then looks at difference with relative humidity.
  - Heat Index
    - Adjusted for birds if available
    - Use just first terms (`c_1 + c_2 T + c_3 R + c_4 T R + ...`) 

### Using VPD as Predictor

- VPD = vapor pressure deficit = actual vapor pressure - saturated vapor pressure
  - VPD = $VPD=vp_{\text{sat}} \times (1-{\text{relative humidity}}/100)$
- `humidity` package provide saturated vapor pressure `SVP()`
  - Note doesn't work with temps in C despite `isK` argument.


### Compare Temp, Humidity, and VPD as predictors

```{r}

thv <- data_ind %>% 
      select(male, temp_mean, humidity_mean, vpd) %>%
      unique() 


# pairs plot
ggpairs(thv %>% select(-male),
        diag = list(continuous = wrap(diag_plots, bins = 8))
        )

```

### Result

- VPD and temp are *highly* correlated

## Model Fitting


### Plots
    
```{r}

xlab = "vpd"


plot_tmp <- ggplot(data) + 
    aes(x = vpd,
        y = motif_prop) +
#    ylim(0, 0.6) + 
    facet_wrap("male", scales = "free_y") +
    geom_point()

plot_glm_vpd <- plot_tmp +
    stat_smooth(method = "glm",
                method.args = list(
                    family = quasipoisson(link = "log"),
                    maxit = 100),
                se = TRUE,
                formula = y ~ 1 + x + I(x^2),
                size = 1
                ) +
    labs( title = paste( ylab, " vs ", xlab, ": unweighted"), 
         subtitle = "glm:y ~quasipoisson(exp[1 + x + x^2])"
         )
last_plot()

plot_glm_vpd_weighted <- plot_tmp + 
    stat_smooth(method = "glm",
                method.args = list(
                    family = quasipoisson(link = "log"),
                    maxit = 100),
                    aes(weight = prop_wt),
                se = TRUE,
                formula = y ~ 1 + x + I(x^2), size = 1,
                ) +
    labs( title = TeX(paste( ylab, " vs ", xlab, ": weight ~ (count_total_round)$^2$)/(motif_count + 1)") ), 
         subtitle = "glm:y ~quasipoisson(exp[1 + x + x^2])"
         )
last_plot()


xlab <- "vpd-$\\bar{vpd}$"

plot_glm_vpd_weighted_centered <- ggplot(data) + 
    aes(x = vpd_offset,
        y = motif_prop) +
    facet_wrap("male", scales = "free_y") +
    geom_point() + 
    stat_smooth(method = "glm",
                method.args = list(
                    family = quasipoisson(link = "log"),
                    maxit = 100),
                    aes(weight = prop_wt),
                se = TRUE,
                formula = y ~ 1 + x + I(x^2), size = 1,
                ) +
    labs( title = TeX(paste( ylab, " vs ", xlab, ": weight ~ (count_total_round)$^2$/(motif_count + 1)")),
         xlab = TeX(xlab), 
         subtitle = TeX("glm:y ~ quasipoisson($\\exp[1 + x + x^2]$)")
         )
last_plot()
```

#### Result

- We do see a concave down curve if we naively fit a quadratic function to the log transformed data.
- Adding `weight = (count_total_round^2)/(motif_count + 1)` greatly improves fit


### Formal Model Fits to `motif_count`


- Using midpoint of vpd
  

```{r}

## Try filtering the data a bit more
## Goal is to get good starting values
count_glm_poisson <- glm(motif_count ~
            1 + vpd_offset + I(vpd_offset^2), 
            data = data_ind %>% filter( !(male %in% c("T231", "T260"))),
        family = poisson(link = "log")
       )
summary(count_glm_poisson)
plot(count_glm_poisson)

count_glm_qpoisson <- glm(motif_count ~
            1 + vpd_offset + I(vpd_offset^2), 
            data = data_ind %>% filter( !(male %in% c("T231", "T260"))),
        family = quasipoisson(link = "log")
)
summary(count_glm_qpoisson)
plot(count_glm_qpoisson)

## Clearly the data is over dispersed
## quasipoisson() doesn't seem to exist for glmer (but likely exists in nlme)

## Try using negative binomial

count_glmer_nb <-
    glmer.nb(motif_count ~ vpd_offset + I(vpd_offset^2) + (vpd_offset|male),
             data = data_ind %>% filter( !(male %in% c("T231", "T260"))),
             ## control values are used by the initial optimization
             ## using a poisson glmer model, which doesn't converge
             control = glmerControl( 
                 optCtrl = list(maxiter = 1E5,
                                maxfun = 2E6,
                                verbose = TRUE,
                                trace = TRUE),
                 optimizer="bobyqa"),
             ## nb.control values are used by the second optimizer
             nb.control = list(
#                 trace = TRUE,
                 maxit = 100,
                 verbose = TRUE)
             )

## Try and fail to use `start` rgument
tmp <- glmer(motif_count ~
            vpd_offset + I(vpd_offset^2) + (vpd_offset + I(vpd_offset^2)||male),
        data = data_ind,
        family = poisson(link = "log"),
        start = list(theta = 4.8, fixef = -0.3515557), #coef,
control = glmerControl(optCtrl = list(maxiter = 1E4, maxfun = 2E6), optimizer="bobyqa"),
    verbose = TRUE)

```

### Result

- Model doesn't converge.
- Output includes 
  > Model is nearly unidentifiable: very large eigenvalue
  > - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
  > - Rescale variables?
  To me this suggests we should use `motif_prop` and the glmer weights function.
  
  

### Formal Model Fits to `motif_prop`


#### Using GLM

- Set `family` to "Gamma" or "Gaussian" and link = 'log'

```{r}


## Gamma has issue with 0 value, so add equivalent of 1 count to every observation (~ like a prior)
glm_gamma <- glm((motif_prop + 1/count_total_round) ~
            1 + vpd_offset + I(vpd_offset^2), 
            data = data_ind %>% filter( !(male %in% c("T231", "T260"))),,
        family = "Gamma"(link = 'log')
       )

summary(glm_gamma)
plot(glm_gamma)

glm_gamma_weighted <- update(glm_gamma,  weights = 1/prop_wt)
summary(glm_gamma_weighted)
plot(glm_gamma_weighted)

anova(glm_gamma, glm_gamma_weighted)


## Even filtered data doesn't behave well
glmer_gamma_filtered <- glmer(
    (motif_prop + 1/count_total_round) ~
            vpd_offset + I(vpd_offset^2) + (vpd_offset||male),
        data = data_ind %>% filter( !(male %in% c("T231", "T260"))),
        family = Gamma(link = "log"),
        control = glmerControl(optCtrl = list(maxiter = 1E4, maxfun = 2E6), optimizer="bobyqa"),
        )


## Wrong model since data is not discrete, gives 400+ pages of warnings
#tmp <- glmer(motif_prop ~
#            vpd_offset + I(vpd_offset^2) + (vpd_offset + I(vpd_offset^2)||male),
#        data = data_ind,
#        family = poisson(link = "log"),
#        weights = prop_wt,
#        control = glmerControl(optCtrl = list(maxiter = 1E4, maxfun = 2E6), optimizer="bobyqa"),
#        verbose = TRUE)
#
#summary(tmp)

```

### Result


## Analyze with rTPC

# Analyze with other packages


According to Padfield et al. (2021)

> However, [the rTPC] pipeline does not accommodate non-independent (related) replicates, and clustered or stratified sampling (possibly with missing values). In such situations, nonlinear mixed effects model fitting (e.g. using the nlme r package; Oddi et al., 2019) or Bayesian approaches (e.g. using the brms r package; Bürkner, 2017) would be more appropriate. Nevertheless, for fitting massive TPC datasets to multiple mathematical models, rTPC offers a simple, reliable and reproducible computational pipeline with robust methods for calculation of model uncertainty, requiring minimal statistical and computational expertise, and suitable for a wide range of applications.

Thus, we can't incorporate random effects.


## `stan`

This is a good excuse to learn how to use `stan`

## 

# End

```{r, error = FALSE}

knitr::knit_exit()

```

#### Using LME -- Uses `nlme` package

```{r}

fm1<-lme(motif_prop ~ exp( 1 + vpd_offset + I(vpd_offset^2)),
         data = data_ind,
         random = ~ 1|male,
         weights = varFixed( ~ 1/prop_wt))  ## this should specify weights = var(motif_prop) 

initialize( varFixed( ~ 1/prop_wt), data_ind)


           
## Try filtering the data a bit more
## Goal is to get good starting values


glm_gaussian <- glm(motif_prop ~
            1 + vpd_offset + I(vpd_offset^2), 
            data = data_ind,
            weights = prop_wt,
        family = "gaussian"(link = 'log')
       )
summary(glm_gaussian)

## Even filtered data doesn't behave well
fit_glmer_initial <- glmer(motif_prop ~
            vpd_offset + I(vpd_offset^2) + (vpd_offset||male),
        data = data_ind %>% filter( !(male %in% c("T231", "T260"))),
        family = gaussian(link = "log"),
        control = glmerControl(optCtrl = list(maxiter = 1E4, maxfun = 2E6), optimizer="bobyqa"),
        )

fit_glmer_qpoisson <- update(fig_glmer_initial, family = quasipoisson())


tmp <- glmer(motif_prop ~
            vpd_offset + I(vpd_offset^2) + (vpd_offset + I(vpd_offset^2)||male),
        data = data_ind,
        family = poisson(link = "log"),
        weights = prop_wt,
        control = glmerControl(optCtrl = list(maxiter = 1E4, maxfun = 2E6), optimizer="bobyqa"),
        verbose = TRUE)

summary(tmp)

```



## GLM Mixed Effects (glmer) Model fits

```{r}

glmer = list()

glmer$poisson <- tmp <-
    glmer(
        motif_count ~
            (1 + temp_mean + (temp_mean||male) + I(temp_mean^2)),
        data = data_ind,
        family = poisson(link = "log"),
        control = glmerControl(optCtrl = list(maxiter = 300)),
        verbose = TRUE)

## Still a lot of overdispersion
glmer$od <- overdisp.glmer(glmer$poisson)

```






# Other Stuff

### Consider estimating overdispersion parameter

```{r}

data_tmp <- data_full %>% filter(round == 2) %>% dplyr::select(male, motif_count) %>% group_by(male)

tmp_summarized <- summarize(data_tmp, var(motif_count), mean(motif_count))

## Methods of Moments: if x ~ NB(p, p/(p + r)), var(x) = p + p^2/r, mean(x) = p
## Alternative parameterization
## p = 1 - \mu/\sigma^2;
## r = \mu^2/(\sigma^2 - \mu)
## Where,
##   \mu = mean(x) = p r/(1-p)
##   \sigma^2 = var(x) = (1-p)/(1+p)^2


var_tmp = var(data_tmp)


tmp <- glm(motif_count ~ male,
           data = data_tmp,
    family = quasipoisson()
    )

```

## Make a model fit tibble - Not complete

```{r}
round_tbl <- tibble(round_1 = FALSE, round_2 = c(TRUE, FALSE),
       round_3 = TRUE
       ) %>% rep(2)



model_cat <- c("lm", "glm", "glmer")
round_1 <- FALSE
round_2 <- c(FALSE, TRUE)
round_3 <- TRUE
male <- c(FALSE, TRUE)
chamber <- c(FALSE, TRUE)
trial_index <- c(FALSE, TRUE)

fit_tbl_names <- c("model_cat",
      "round_1",
      "round_2",
      "round_3",
      "male",
      "chamber",
      "trial_index",
      "temp_slope",
      "temp_curve",
      "male_x_temp_slope",
      "male_x_temp_curve",
      "residual_df".
      "residual_ss"
      "R2",
      "AIC",
      "fit_obj"
      )

fit_tbl <- data.frame("a" = 1, "b"= 1:2, "c" = 1:3)

                 ,
                  names = 
      )
)
comment(fit_tbl) <- "temp_slope = temp, temp_curve = I(temp^2)"

filter_data_lm() <- list(
formulas_lm() <-
    


```

## Earliest Analysis

### Analyze `round 2 & 3`

- In `round = 3`, 
  - The only `trial_completed = FALSE` is in highest temp.
  - Only one of 6 chambers was used for a given male, thus chamber and male are conflated.
  - Actually makes life easier!

```{r}

data_r3 <- data_full %>% filter(round ==3)

```
### LM Fits on `log(motif_counts_plus_one)`

- None of these models fit very well



#### Fit each individual separately

- Learning how to use `lmList()` function

```{r}

## Individual fits to each male
## This isn't that useful, but is my firstuse of lmList()

lmList <- list()

lmList$by_male <- tmp <-
    lme4::lmList(log_motif_count_plus_1 ~ 1 + temp_target + I(temp_target^2) | male,
           data = data %>% filter(round %in% c(2,3)),
           na.action = na.omit)
           

summary(tmp)

plot.lmList4(tmp, log_motif_count_plus1 ~ fitted(.)| male)


```
#### Fit multiple variations of grouping

```{r}


lm = list()

formula <- as.formula("log_motif_count_plus_1 ~ 1 + temp_target + I(temp_target^2)")

## Note syntax below model `formula` doesn't appear in the model summary().
## lm$basic <- lm(formula = formula , data = data_r3)

## Here string of formula is shown in summary()
## The .() forces the evaluation in bquote()
## See: https://win-vector.com/2018/09/01/r-tip-how-to-pass-a-formula-to-lm/
## for detailed explanation of how this works
lm$basic <- tmp <- eval(bquote(lm(formula = .(formula) , data = data_r3)))
summary(tmp)

## Add trial_index effect
formula <- as.formula("log_motif_count_plus_1 ~ 1 + trial_index+ temp_target + I(temp_target^2)")
lm$trial_index <- tmp <- eval(bquote(lm(formula = .(formula) , data = data_r3) ))
summary(tmp)

## Add male effect 
formula <- as.formula("log_motif_count_plus_1 ~ 1 + male + temp_target + I(temp_target^2)")
lm$male <- tmp <- eval(bquote(lm(formula = .(formula) , data = data_r3)))
summary(tmp) 

## Add chamber effect (fewer chambers than males)
formula <- as.formula("log_motif_count_plus_1 ~ 1+ chamber + temp_target + I(temp_target^2)")
lm$chamber <- tmp <- eval(bquote(lm(formula = .(formula) , data = data_r3)))
summary(tmp)

## Add trial_index and male effects
formula <- as.formula("log_motif_count_plus_1 ~ 1 + trial_index + male + temp_target + I(temp_target^2)")
lm$trial_index_and_male <- tmp <- eval(bquote(lm(formula = .(formula) , data = data_r3) ))
summary(tmp)


## Add male x trial order
## This doesn't work since we have as many coefficients as data points.
## Oops
formula <- as.formula("log_motif_count_plus_1 ~ 1 + male*trial_index + temp_target + I(temp_target^2)")
lm$trial_index_by_male <- tmp <- lm(formula = eval(formula) , data = data_r3)
summary(tmp)


## add slope x male interaction term

lm$male_by_temp <- tmp <- lm(formula = log_motif_count_plus_1 ~ 1 + temp_target*male + I(temp_target^2), data = data_r3)
summary(tmp)


## slope x male - male intercept
## This suggests that the slopes are similar between males (though the SE are large)
lm$male_by_temp <- tmp <- lm(formula = log_motif_count_plus_1 ~ 1 + temp_target:male + I(temp_target^2), data = data_r3)
summary(tmp)

## curvature x male - male intercept
## This suggests that the slopes are similar between males (though the SE are large)
lm$male_by_temp_sq <- tmp <- lm(formula = log_motif_count_plus_1 ~ 1 + temp_target + I(temp_target^2):male, data = data_r3)
summary(tmp)
```

## GLMM (glmer) Model fits

```{r}

glmer = list()

## I think this is a correct fit.  If I don't include the 1 + temp... w/o the |male, I don't get any effects.
glmer$nb_1 <- glmer.nb(
    motif_count ~ 1 + temp_target + I(temp_target^2) + trial_index + ((1 + temp_target + I(temp_target^2))|male),
    data = data_r3,
    family = poisson(link = "log"),
    control = glmerControl(optCtrl = list(maxiter = 300)),
    verbose = TRUE)


glmer$nb_2 <- update(glmer$nb_1, formula =  motif_count ~ 1 + temp_target + I(temp_target^2) + ((1 + temp_target + I(temp_target^2))|male) )

mode
```


### Compare Models

```{r}


## Results: Male is much better predictor than trial_index
anova(lm$male, lm$trial_index)

## Results: Male is better predictor than chamber.
## This indicates males vary more than chambers
anova(lm$male, lm$chamber)

## Results: Adding trial_index to male provides no real gain in fit
anova(lm$male, lm$trial_index_and_male)
```

### Notes

- We do see evidence of male effects.
  The important males have lower intercepts than the rest
- There is little evidence of consistent trial_index effects.
- Adjusted $R^2$ don't seem to vary much.


## For Later: Lactin2 

```{r}

data <- data_full %>% filter(round ==3)

data %>% group_by(temp_target) %>%
    filter(motif_count < 400) %>%
    summarize(ave = mean(motif_count, na.rm = TRUE), sd = sd(motif_count, na.rm = TRUE)) 


## show the data
## windows()
ggplot(data, aes(temp_target, motif_count)) + 
    geom_point() +
    geom_jitter() +
  theme_bw(base_size = 12) +
  labs(x='Temperature (C)', 
       y='Song Count', 
       title = 'Song Count Across Temperature')

## choose the model
mod = 'lactin2_1995'

## get starting values
start_vals <- get_start_vals(data$temp_target, data$motif_count, model_name = 'lactin2_1995')
  
## Get limits
low_lims <- get_lower_lims(data$temp_target,data$motif_count,model_name = 'lactin2_1995')
upper_lims <- get_upper_lims(data$temp_target, data$motif_count, model_name = 'lactin2_1995')

start_vals
low_lims
upper_lims
  
## fit model
fit <- nls_multstart(motif_count~lactin2_1995(temp = temp_target, a,b,tmax,delta_t),
                                  data = data,
                                  iter = 600,
                                  start_lower = start_vals-10,
                                  start_upper = start_vals+10,
                                  lower = low_lims,
                                  upper = upper_lims,
                                  supp_errors = 'Y',
                                  convergence_count = FALSE)
  
## look at model fit
summary(fit)

## Predict new data 
preds <- data.frame(temp = seq(min(data$temp_target), max(data$temp_target), length.out = 6))
preds <- broom::augment(fit, newdata = preds)

## plot data and model fit
## windows()
ggplot(preds)+
  geom_point(aes(temp_target,motif_count), data)+
  geom_line(aes(temp, .fitted), preds, col = 'blue')+
  theme_bw()+
  labs(x='Temperature (C)',
       y='Song Count',
       title = 'Song Count Across Temperatures')


```


## Unweighted model

- Fit 4 Chosen model formulations in rTPC


```{r}

d <-filter(heat_roundt2, Male =="T236")
d_fits <- nest(d, data = c(temp_target,motif_count)) %>%
  mutate(lactin = map(data,~nls_multstart(motif_count~lactin2_1995(temp = temp_target, a, b, tmax, delta_t),
                      data = .x,
                      iter = c(3,3,3,3),
                      start_lower = get_start_vals(.x$temp_target, .x$motif_count, model_name = 'lactin2_1995')-10,
                      start_upper = get_start_vals(.x$temp_target, .x$motif_count, model_name = 'lactin2_1995')+10,
                      lower = get_lower_lims(.x$temp_target, .x$motif_count, model_name = 'lactin2_1995'),
                      upper= get_upper_lims(.x$temp_target, .x$motif_count, model_name = 'lactin2_1995'),
                      supp_errors = 'Y',
                      convergence_count = FALSE)),
weibull = map(data,~nls_multstart(motif_count~weibull_1995(temp = temp_target, a, topt, b,c),
                                  data = .x,
                                  iter = c(4,4,4,4),
                                  start_lower = get_start_vals(.x$temp_target, .x$motif_count, model_name = 'weibull_1995')-10,
                                  start_upper = get_start_vals(.x$temp_target, .x$motif_count, model_name = 'weibull_1995')+10,
                                  lower = get_lower_lims(.x$temp_target, .x$motif_count, model_name = 'weibull_1995'),
                                  upper= get_upper_lims(.x$temp_target, .x$motif_count, model_name = 'weibull_1995'),
                                  supp_errors = 'Y',
                                  convergence_count = FALSE)),
modifiedgaussian = map(data, ~nls_multstart(motif_count~modifiedgaussian_2006(temp = temp_target, rmax,topt, a, b),
                                            data = .x,
                                            iter = c(3,3,3,3),
                                            start_lower = get_start_vals(.x$temp_target, .x$motif_count, model_name = 'modifiedgaussian_2006')-10,
                                            start_upper = get_start_vals(.x$temp_target, .x$motif_count, model_name = 'modifiedgaussian_2006')+10,
                                            lower = get_lower_lims(.x$temp_target, .x$motif_count, model_name = 'modifiedgaussian_2006'),
                                            upper= get_upper_lims(.x$temp_target, .x$motif_count, model_name = 'modifiedgaussian_2006'),
                                            supp_errors = 'Y',
                                            convergence_count = FALSE)),
briere = map(data,nls_multstart(motif_count~briere2_1999(temp = temp_target, tmin, tmax, a,b),
                                data = .x,
                                iter = c(4,4,4,4),
                                start_lower = get_start_vals(.x$temp_target, .x$motif_count, model_name = 'briere2_1999')-10,
                                start_upper = get_start_vals(.x$temp_target, .x$motif_count, model_name = 'briere2_1999')+10,
                                lower = get_lower_lims(.x$temp_target, .x$motif_count, model_name = 'briere2_1999'),
                                upper= get_upper_lims(.x$temp_target, .x$motif_count, model_name = 'briere2_1999'),
                                supp_errors = 'Y',
                                convergence_count = FALSE)))
