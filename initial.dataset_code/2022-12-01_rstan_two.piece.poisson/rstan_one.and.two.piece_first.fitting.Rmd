---
title: "Piecewise Regression using STAN Directly"
author: "Michael Gilchrist"
date: "date: 2022-11-29"
output: pdf_document
---

```{r setup, include=FALSE, }
knitr::opts_chunk$set(
  warning = TRUE, # show warnings
  message = TRUE, # show messages
  error = TRUE, # do not interrupt generation in case of errors,
  echo = TRUE  # show R code
)


if(interactive()) default::default(.ess.eval) <- list(max.deparse.length=1E3, output = TRUE)

```
# Goal

- Fit one and two piece Poisson and Quasiposson GLM 

## Recap

# Set up

## Install libraries

```{r, message = FALSE}

# install packages user might not have by replacing FALSE with TRUE

## load libraries
library(stats)
library(MASS) # provides negative binomial fitting:  glm.nb
library(ggplot2)
library(ggpubr)
library(grid)
library(gridExtra)
library(GGally)
library(broom)
library(tidyverse)
library(viridisLite)
library(rstan)
options(mc.cores = (parallel::detectCores()-2))
rstan_options(auto_write = TRUE)
library(loo)


## options(ggplot2.continuous.colour="viridis",
##        ggplot2.discrete.colour="viridis",
##        ggplot2.scale_fill_discrete = scale_fill_viridis_d,
##        ggplot2.scale_fill_continuous = scale_fill_viridis_c)

library(reshape2)
library(lme4)
library(latex2exp)

```

## Load Data

```{r}
load(file.path("input", "data.processing_2022-11-09.Rda"),
     verbose = TRUE)

```


# Examine Data

## Create Working Dataset

```{r}

filter_data <- TRUE

if(filter_data) {
  males_filtered_disp <- motif_stats_40C %>%
    filter(dispersion < 50) %>%
    pull(male)

  males_filtered_mean <- motif_stats %>%
    filter(mean > 10) %>%
    pull(male)

  male_vector <- intersect(males_filtered_mean, males_filtered_disp)
} else {
  male_vector <- motif_data %>% select(male) %>% distinct()
}


##males_selected <-

data_ind <- motif_data %>%
  filter(male %in% male_vector) %>%
  arrange(male) %>%
  ##    left_join(male_shape, by = "male") %>%
  mutate()

stats_ind <- motif_stats %>%
  filter(male %in% male_vector)

```


## Plot motif_count


```{r, echo = FALSE}

g1 <- ggplot(data = data_ind) +
  aes(x = temp, y = motif_count, color = male, shape = male) +
  ## Redefine shapes. Note need to set 'shape = male' above to prevent there from
  ## begin two legends: 1 for shape and 1 for color.
  scale_shape_manual(values = rep(c(16:18), length.out = length(male_vector))) +
  geom_point() +
  scale_color_viridis_d() +
  labs(title = "motif_count") +
  theme(legend.position="none")

g2 <- ggplot(data = data_ind) +
  aes(x = temp, y = motif_prop, color = male, shape = male) +
  scale_shape_manual(values = rep(c(16:18), length.out = length(male_vector))) +
  geom_point() +
  scale_color_viridis_d() +
  labs(title = "motif_prop") +
  theme(legend.position="bottom")


legend <- get_legend(g2)

g2 <- g2 + theme(legend.position="none")

g3 <- tableGrob(format(
  data.frame(stats_ind %>%
               select(male, n_obs, total, mean) %>% unique()),
  digits = 1),
  theme = ttheme_default(base_size = 8))

grid.arrange(g1, g2, g3, legend, ncol = 2,
             top=textGrob("Males filtered for dispersion < 50 at 40C & count_mean < 10",
                          gp=gpar(fontsize = 11))
             )


```

# Analyze Data:


## Simple GLM


```{r}

glm_poisson_0 <- glm(motif_count ~
                        1,
                      data = data_ind,
                      family = poisson(link = "identity")
                      )

summary(glm_poisson_0)

glm_qpoisson_0 <- glm(motif_count ~
                        1,
                      data = data_ind,
                      family = quasipoisson(link = "identity")
                      )

summary(glm_qpoisson_0)

# Following analysis not needed
#
# glm_qpoisson_1 <- glm(motif_count ~
#                        (1 + male),
#                      data = data_ind,
#                      family = quasipoisson(link = "identity")
#                      )
#
#
#summary(glm_qpoisson_1)

```

# Stan


## Set Up Data

```{r}

motif_count <- data_ind %>% pull(motif_count)
temp <- data_ind %>% pull(temp)
N <- length(temp)
## parameters to be printed

pars <- c("t1", "y0")
pars_full <- c(pars, "b1", "lp__")
```
## Normal error

```{r}

iter <- 6000 ## increasing to 10k doesn't really help
fit_norm <- stan(file = "two.piece_normal.stan",
              model_name = "Two piece gaussian",
              data=list(x = temp, y = motif_count,
                        N = N,
                        tmax = 46,
                        y_tmax = 0),
              chains = 4,
              cores = 4,
              iter = iter,
              warmup = iter/2)
```

- Even with a (poorly chosen) prior on sigma, this fails to converge.
Here's some output.
````{verbatim}

> Chain 1: Iteration: 6000 / 6000 [100%]  (Sampling)
> Chain 1: 
> Chain 1:  Elapsed Time: 15.038 seconds (Warm-up)
> Chain 1:                14.647 seconds (Sampling)
> Chain 1:                29.685 seconds (Total)
> Chain 1: 
> Warning messages:
> 1: There were 1 divergent transitions after warmup. See
> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
> to find out why this is a problem and how to eliminate them. 
> 2: There were 3819 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See
> https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded 
> 3: Examine the pairs() plot to diagnose sampling problems
>  
> 4: The largest R-hat is 1.55, indicating chains have not mixed.
> Running the chains for more iterations may help. See
> https://mc-stan.org/misc/warnings.html#r-hat 
> 5: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
> Running the chains for more iterations may help. See
> https://mc-stan.org/misc/warnings.html#bulk-ess 
> 6: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
> Running the chains for more iterations may help. See
> https://mc-stan.org/misc/warnings.html#tail-ess 

````

## Poisson: Threshold (`t1`) and slope (`b`) formulation

- Model can be fitted
  - Data is overdispersed.
    (See comparison to `quasipoisson` below.)
  - Alternative formulation trying to estimate 'y0' directly does not currently work.

### Null Model

```{r}

iter <- 5000
tmax <- 46
t1min <- 25
t1max <- tmax - 0.001
t1min <- t1max - 0.001
## values to use for model predictions
tp = seq(25, t1max, length.out = 100)

fit_1 <- stan(file = "two.piece_poisson.stan",
              model_name = "one step poisson",
              data=list(t = temp,
                        y = motif_count,
                        N = N,
                        tmax = tmax,
                        t1min = t1min,
                        t1max = t1max, ## max threshold value.
                        ## having it too close to tmax *sometimes* leads to sampling
                        ## near tmax, but with lower lp and very high E13) b1 values
                        y_tmax = 0,
                        tp = tp),
              chains = 4,
              cores = 4,
              iter = iter,
              warmup = floor(iter/2))

## Examine output
main <- "One piece"
print(main)



print(fit_1, pars = pars)
traceplot(fit_1, pars = pars, inc_warmup = FALSE, main = main)
plot(fit_1, pars = pars, main = main)
pairs(fit_1, pars = pars_full, main = main)
main = paste0("t1max = ", t1max)
```

## Two Piece Model

- Examination of posterior pr values indicate this fits substantially better than the one piece model.
- LOO analysis below indicates it has more `problems`, however.

```{r}

iter <- 5000
tmax <- 46
t1max <- tmax - 0.75;
t1min <- 25;
## values to use for model predictions
tp = seq(25, tmax, length.out = 100)

fit_2 <- stan(file = "two.piece_poisson.stan",
              model_name = "Two Piece poisson",
              data=list(t = temp,
                        y = motif_count,
                        N = N,
                        tmax = tmax,
                        t1min = t1min,
                        t1max = t1max, ## max threshold value.
                        ## having it too close to tmax *sometimes* leads to sampling
                        ## near tmax, but with lower lp and very high E13) b1 values
                        y_tmax = 0,
                        tp = tp),
              chains = 4,
              cores = 4,
              iter = iter,
              warmup = floor(iter/2))

## Examine output
main <- "Two piece"
print(main)
print(fit_2, pars = pars)
traceplot(fit_2, pars = pars, inc_warmup = FALSE, main = main)
plot(fit_2, pars = pars, main = main)
pairs(fit_2, pars = pars_full, main = main)

#ggplot()
```

### Leave One Out (LOO) analysis


```{r}
## Code from:
# Extract pointwise log-likelihood
# using merge_chains=FALSE returns an array, which is easier to 
# use with relative_eff()
for(fit in c("fit_1", "fit_2")) {
  print(paste0("Model Fit: ", fit))  
  log_lik_1 <- extract_log_lik(eval(parse(text = fit)), merge_chains = FALSE)
# as of loo v2.0.0 we can optionally provide relative effective sample sizes
# when calling loo, which allows for better estimates of the PSIS effective
# sample sizes and Monte Carlo error
r_eff <- relative_eff(exp(log_lik_1), cores = 2) 

# preferably use more than 2 cores (as many cores as possible)
# will use value of 'mc.cores' option if cores is not specified
loo_1 <- loo(log_lik_1, r_eff = r_eff, cores = 2)
  print(loo_1)
}

```
- Don't really know how to interpret these results.


## Comparing Fits


### Null Models: GLM\_Poisson, GLM\_Quasipoisson vs. STAN Poisson

```{r}

summary(glm_poisson_0)
summary(glm_qpoisson_0)
print(fit_1, pars = c("y0"))

```
- We see that all three approaches give the same best estimate of `y0 = 116.5`.
  In addition,
  - `poisson` and `stan` fits match in terms of their error estimate: 1.05.
    This is substantially smaller than the `quasipoisson` estimate of 8.25.
    I was hoping that the `stan` model would match the `quasipoisson` estimates.
      


```{r}
knitr::knit_exit()
```


### Plot One vs. Two Piece

```{r}

fit <- fit_1

yp_summary <- extract(fit)$yp %>% data.frame() %>% t()#%>% transmute(mean = across(everything(), mean))

%>% transmute(
                                         mean = mean(yp),
                                         lci = quantile(yp, 0.025),
                                         uci = quantile(yp, 0.975)
                                         )

## get xy predictions
xyp_tibble <- tibble(xp = tp, yp = t(yp)) #%>% unnest(cols = yp)


)xyp_summary <- xyp_tibble %>% transmute(x = tp, y = mean(yp), lci = quantile(yp, 0.025), uci = quantile(yp, 0.975))


g1 + geom_smooth(
       

```


# CRUFT

### Threshold (`t1`) and pre-threshold level (`y0`) formulation


- This has problems when run so, until they are debugged, don't run.
Instead, use previous model that calculates y0 from `t1` and `b0`.

```{r}

iter <- 6000
t1max = 45

fit_3 <- stan(file = "one.step_piecewise_poisson_t1.and.y0.stan",
              model_name = "one step poisson: ",
              data=list(t = temp,
                        y = motif_count,
                        N = N,
                        tmax = 46,
                        t1min = t1min, ## min threshold value
                        t1max = t1max, ## max threshold value
                        ## having it too close to tmax *sometimes* leads to sampling
                        ## near tmax, but with lower lp and very high E13) b1 values
                        y_tmax = 0),
              chains = 4,
              cores = 4,
              iter = iter,
              warmup = iter/2)

## Examine output
main = paste0("t1max = ", t1max)
print(main)
print(fit_2)
traceplot(fit_2, pars = c("t1", "y0", "lp__"), inc_warmup = FALSE, main = main)
plot(fit_2, pars = c("t1", "y0", "lp__"), main = main)
pairs(fit_2, pars = c("t1", "y0", "lp__"), main = main)


```




## Stan data example
```{r}

y_1 <- c(3, 5)
y_2 <- rep(c(2,3,4,5), c(10,20,30,40))
y <- c(y_1, y_2)
N <- length(y)
movie <- rep(c(1,2), c(length(y_1), length(y_2)))
movie_data <- list(y=y, N=N, movie=movie)
#fit_1 <- stan("ratings_1.stan", data=movie_data)

```
